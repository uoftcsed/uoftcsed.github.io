inproceedings{02Bulbulia25,
author = {Yousef Bulbulia and Ido Ben Haim and Jackson Lee and Brian Zhang and Daksh Malhotra and Andrew Petersen and Michael Liut},
title = {Codetierlist: Competitive Gamification's Impact on Self-Efficacy, Motivation, and Performance in Computing Education},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716646},
doi = {10.1145/3716640.3716646},
abstract = {Students struggle to understand why rigorous testing is necessary, often testing with a small number of examples and testing interactively instead of through a framework. Our goal is to encourage students to meaningfully engage in the testing process. We do so by developing a system, Codetierlist, that gamifies the process of testing on a programming assignment in a first-year programming course (CS2). Student tests for a programming assignment are run against both the instructor solution and other student solutions, and students receive feedback, in the form of a tier-based ranking, on how well their solution compares to fellow students within the shared student test suite. We compared the tests and assignment solutions students produced with and without Codetierlist. We also gathered student and instructor feedback on the experience of using the tool and measured student motivation and self-efficacy regarding testing. Students wrote more functionally correct code with Codetierlist, and they wrote significantly more and more precise tests with Codetierlist, even identifying previously unknown bugs in the instructor solution. We did not detect any changes to student self-efficacy, but students reported feeling more positive about testing and more motivated to test with Codetierlist. However, we also detected negative effects from the gamification method selected, as some students whose code was placed in a lower tier felt discouraged and less able to succeed. Additionally, we found that improvements to motivation and efficacy may vary based on a student’s prior experience. We provide the community with a tool, Codetierlist, for motivating students to engage more actively with testing in an assignment setting, and identify positive aspects of providing students with a target to test against. However, we reiterate the need for caution when introducing gamified elements that might be viewed as encouraging competition, as students who receive negative feedback from a comparison may feel unable to improve their situation.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {46–55},
numpages = {10},
keywords = {Testing, CS2, Programming, Gamification, Computing Education},
location = {
},
series = {ACE '25}
}

article{01Zhu25,
  author = {Tingting Zhu and Rutwa Engineer and Xaria Prempeh and Anna Ly and Michelle Craig and Andrew Petersen},
  title     = {Comparing physical analogue and traditional videos for learning and emotional engagement},
  journal   = {Discovery Education},
  volume    = {4},
  pages     = {71},
  year      = {2025},
  doi       = {10.1007/s44217-025-00454-1},
  url       = {https://doi.org/10.1007/s44217-025-00454-1}
}

@Article{12Falkner24,
  author = {Nick Falkner and Juho Leinonen and Miranda C. Parker and Andrew Petersen and Claudia Szabo},
  title =	{{A Game of Shadows: Effective Mastery Learning in the Age of Ubiquitous AI (Dagstuhl Seminar 24272)}},
  pages =	{245--262},
  journal =	{Dagstuhl Reports},
  ISSN =	{2192-5283},
  year =	{2024},
  volume =	{14},
  number =	{6},
  editor =	{Falkner, Nick and Leinonen, Juho and Parker, Miranda C. and Petersen, Andrew and Szabo, Claudia},
  publisher =	{Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address =	{Dagstuhl, Germany},
  URL =		{https://drops.dagstuhl.de/entities/document/10.4230/DagRep.14.6.245},
  URN =		{urn:nbn:de:0030-drops-227277},
  doi =		{10.4230/DagRep.14.6.245},
  annote =	{Keywords: chatgpt, computing education, llms, machine learning, mastery learning}
}

@inproceedings{12Lewis24,
author = {Colleen M. Lewis and Craig S. Miller and Johan Jeuring and Janice L. Pearce and Andrew Petersen},
title = {Hash Table Notional Machines: A Comparison of 2D and 3D Representations},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690118},
doi = {10.1145/3649165.3690118},
abstract = {Background: Notional machines appear to be an essential aspect of computing education, but there are few papers that identify strengths and weaknesses of particular notional machines. Purpose: This article fills a gap in the notional machine literature by using a randomized controlled trial to compare the effectiveness of different notional machine representations. Methods: Our study used notional machines for two hash table algorithms: chaining and open addressing. Students were randomly assigned a video sequence using either 2D or 3D representations. Findings: We found minimal effect of 2D vs 3D representational form on students' learning and perceptions of helpfulness. Implications: Our paper provides an example of how educational research can inform the design and evaluation of notional machines.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {109–115},
numpages = {7},
keywords = {hash tables, hashset, java, notional machine},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

inproceedings{08Sibia24,
author = {Naaz Sibia and Angela Zavaleta Bernuy and Tiana V. Simovic and Chloe Huang and Yinyue Tan and Eunchae Seong and Carolina Nobre and Daniel Zingaro and Michael Liut and Andrew Petersen},
title = {Exploring the Effects of Grouping by Programming Experience in Q&A Forums},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671107},
doi = {10.1145/3632620.3671107},
abstract = {Motivation: Q&A forums are a critical resource for supporting students in large educational environments, yet students often perceive these forums as stressful and report discomfort in participating visibly, especially in classes that are large and have students with varying levels of prior programming experience (PE). Method: We divided students in a CS1 Q&A forum into smaller, homogenous groups based on their PE. We use a mixed-methods approach to compare data from this experience to data from a setting where all students shared a single, large Q&A forum (a “mixed” setting). We quantitatively analyze measures of student engagement and use an open-ended qualitative approach to examine responses about student experience on the forums. This approach helps us identify the motivation behind student decisions to participate in visible or non-visible ways and to evaluate their alignment with theoretical frameworks. Results: In the mixed setting, students frequently use anonymity, with students without PE using anonymity more than students with PE and women using anonymity more than men. In contrast, in the homogenous groups, novices used anonymity less than novices in the mixed setting, while the students in higher-experience groups tended to use it more. We also observe a reduced anonymity usage among women in the homogenous experience groups, suggesting that PE plays a critical role in the observed gender disparities in forum participation. The qualitative analysis provides additional evidence that social status issues and confidence may explain these behavioral patterns. Conclusion: This study highlights the potential benefits and consequences of grouping students by experience. Homogenous PE groups foster increased student comfort and engagement within the Q&A forum for students with less experience, but students with more experience are exposed to more perceived status threats. We discuss how these results align with the theories we used to design the homogenous group setting. This exploration contributes to a deeper understanding of the underlying dynamics shaping student behavior in online learning communities. Educators and platform designers can use these lessons to more effectively create inclusive environments that accommodate diverse student needs and preferences.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {206–221},
numpages = {16},
keywords = {Anonymity, Confidence, Prior Experience, Q&A Forums},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

inproceedings{06Zavaleta24,
author = {Angela Zavaleta Bernuy and Naaz Sibia and Pan Chen and Jessica Jia-Ni Xu and Elexandra Tran and Runlong Ye and Viktoria Pammer-Schindler and Andrew Petersen and Joseph Jay Williams and Michael Liut},
title = {Does the Medium Matter? An Exploration of Voice-Interaction for Self-Explanations},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661596},
doi = {10.1145/3643834.3661596},
abstract = {This research evaluates voice-based self-explanations as a pedagogical tool in preparation for lectures, assesses user preferences between voice and text, and derives design insights. We report two studies: Study 1, a quasi-experimental field study, with 247 participants divided into voice-based (N = 83), text-based (N = 81), and choice (N = 83) conditions. Study 2 uses semi-structured interviews (N = 16) to explore perceptions of the interaction paradigms in-depth. Results from the first study revealed a general preference for text, though voice users produced longer responses and more topic-related keywords. Over time, the preference for voice increased among students, from 10\% to 46\%, when given a choice. Study 2 suggested that factors like social presence contribute to hesitance toward voice-based explanations, with a cognitive load, self-confidence, and performance anxiety also influencing medium preferences. Our findings highlight design recommendations and demonstrate the potential of voice-based self-explanations in educational settings, indicating that mixed interfaces might better meet diverse needs.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {86–101},
numpages = {16},
keywords = {Active Learning, Explanation Prompts, Long-Term Memory, Self-Explanations, Student Performance, Text Explanations, Voice Explanations, Voice-based Interaction},
location = {IT University of Copenhagen, Denmark},
series = {DIS '24}
}

inproceedings{04Sibia24,
author = {Naaz Sibia and Angela Zavaleta Bernuy and Elexandra Tran and Jessica Jia-Ni Xu and Joseph Jay Williams and Andrew Petersen and Michael Liut},
title = {Exploring Self-Explanations in a Flipped Database Course},
year = {2024},
isbn = {9798400706783},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663649.3664374},
doi = {10.1145/3663649.3664374},
abstract = {Self-explanations show promise for engaging students with preparatory materials, yet research into the types of self-explanations submitted in computing is limited. This paper examines student perceptions of self-explanation prompts in a flipped databases course, building on existing research that highlights the advantages of self-explanations in such contexts. We present our findings on students’ perceptions of the utility of self-explanation prompts and analyze
the nature of the explanations generated across distinct topics. The results suggest that self-explanations not only facilitate a deeper understanding of the subject matter but also promote the discovery of new connections and examples through rewording explanations. Furthermore, errors within self-explanations offer valuable insights for the early identification of misconceptions.},
booktitle = {Proceedings of the 3rd International Workshop on Data Systems Education: Bridging Education Practice with Education Research},
pages = {20–26},
numpages = {7},
keywords = {Active Learning, Flipped Databases Course, Self-Explanations},
location = {Santiago, AA, Chile},
series = {DataEd '24}
}

inproceedings{05Zavaleta24,
author = {Angela Zavaleta Bernuy and Andrew Chung and Alana Hodge and Ayesha Tayyiba and Michael Liut and Andrew Petersen},
title = {Student Transitions Through an Entire Computing Program},
year = {2024},
isbn = {9798400709975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660650.3660661},
doi = {10.1145/3660650.3660661},
abstract = {While the challenges experienced by first-year computing students have been well studied, little work has explored the transitions in disciplinary participation and challenges experienced by upper-years. This study explores how students’ needs and challenges evolve through a computing degree. We collected the experiences of first to final-year undergraduate computing students through surveys and interviews. We organized these experiences into themes that we compare against previous literature and illustrate with quotes. Upper-year students perceive changes in (a) levels of support and (b) the kinds of challenges they experience as they progress through the program. Second-year students feel pressured by the increasing difficulty of courses. This pressure increases through the third year as students begin to perceive a need to find employment. The experiences of our students suggest the need to better support the middle years of academic programs. Students in the first year are well-supported in their university transition, but students in the middle are often left to find their way as they develop a deeper understanding of their desired place in the field.},
booktitle = {The 26th Western Canadian Conference on Computing Education},
articleno = {5},
numpages = {7},
keywords = {CS1, student experience, transition, upper-year},
location = {<conf-loc>, <city>Kelowna</city>, <state>BC</state>, <country>Canada</country>, </conf-loc>},
series = {WCCCE '24}
}

inproceedings{03Sibia24,
author = {Naaz Sibia and Giang Bui and Bingcheng Wang and Yinyue Tan and Angela Zavaleta Bernuy and Christina Bauer and Joseph Jay Williams and Michael Liut and Andrew Petersen},
title = {Examining Intention to Major in Computer Science: Perceived Potential and Challenges},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630843},
doi = {10.1145/3626252.3630843},
abstract = {This study explores links between attributes of computing students, such as prior programming experience (PE) and gender, with expectations for success and the perception of challenges. Using Expectancy-Value Theory (EVT), we investigate their major intentions and the impact of these factors post-CS1. Data was gathered using surveys at the beginning and end of an introductory programming course, focusing on demographics, expectations of success, and perceptions of challenges. Application status for the computing major was also recorded. Our results revealed that men and students with PE generally perceived greater potential for success and reported facing fewer challenges. In contrast, women and students without PE more often indicated concerns about intellectual ability and perceived challenges less positively. Notably, while gender appears in the preceding results, an intersectional analysis indicates that PE is the central factor. PE is also linked to persistence in the field of computing. Our results further highlight the importance of providing students with opportunities to develop experience, as it can help shape their expectations, perceived challenges, and retention in computing.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1237–1243},
numpages = {7},
keywords = {gender, prior experience, program retention, self-efficacy},
location = {<conf-loc>, <city>Portland</city>, <state>OR</state>, <country>USA</country>, </conf-loc>},
series = {SIGCSE 2024}
}

inproceedings{01Zavaleta23,
author = {Angela Zavaleta Bernuy and Runlong Ye and Elexandra Tran and Naaz Sibia and Abhijoy Mandal and Hammad Shaikh and Bogdan Simion and Michael Liut and Andrew Petersen and Joseph Jay Williams},
title = {Do Students Read Instructor Emails? A Case Study of Intervention Email Open Rates},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631813},
doi = {10.1145/3631802.3631813},
abstract = {Email is an important mode of communication because it scales to the largest computing courses and is institutionally supported. Furthermore, regular email communication from instructors has been shown to help set student expectations and encourage participation. As a result, effective email can contribute to emotional engagement, which has been linked to improvements in performance and retention, the latter being a persistent problem in computer science. However, we lack a clear picture of how computing students interact with emails and whether their use aligns with instructors’ expectations. This paper addresses this gap by presenting data on how often CS1 students open instructor emails. We present email engagement data throughout the term for a particular type of email that prompts students to plan to start their homework. Contrary to instructors’ expectations, the rate at which students open emails of this kind does not change significantly over the term. Many students who engage with the emails do so consistently, even after repeated emails throughout the term. The patterns we found illustrate the value of collecting this type of data and informing instructors and researchers about who reads these messages and how often they actually reach students.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {13},
numpages = {12},
keywords = {email engagement, email open rates, instructor communication},
location = {<conf-loc>, <city>Koli</city>, <country>Finland</country>, </conf-loc>},
series = {Koli Calling '23}
}

@inproceedings{12Petersen23,
author = {James Prather and Paul Denny and Juho Leinonen and Brett A. Becker and Ibrahim Albluwi and Michelle Craig and Hieke Keuning and Natalie Kiesler and Tobias Kohn and Andrew Luxton-Reilly and Stephen MacNeil and Andrew Petersen and Raymond Pettit and Brent N. Reeves and Jaromir Savelka},
title = {The Robots Are Here: Navigating the Generative AI Revolution in Computing Education},
year = {2023},
isbn = {9798400704055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623762.3633499},
doi = {10.1145/3623762.3633499},
abstract = {Recent advancements in artificial intelligence (AI) and specifically generative AI (GenAI) are threatening to fundamentally reshape computing and society. Largely driven by large language models (LLMs), many tools are now able to interpret and generate both natural language instructions and source code. These capabilities have sparked urgent questions in the computing education community around how educators should adapt their pedagogy to address the challenges and to leverage the opportunities presented by this new technology. In this working group report, we undertake a comprehensive exploration of generative AI in the context of computing education and make five significant contributions. First, we provide a detailed review of the literature on LLMs in computing education and synthesise findings from 71 primary articles, nearly 80\% of which have been published in the first 8 months of 2023. Second, we report the findings of a survey of computing students and instructors from across 20 countries, capturing prevailing attitudes towards GenAI/LLMs and their use in computing education contexts. Third, to understand how pedagogy is already changing, we offer insights collected from in-depth interviews with 22 computing educators from five continents. Fourth, we use the ACM Code of Ethics to frame a discussion of ethical issues raised by the use of large language models in computing education, and we provide concrete advice for policy makers, educators, and students. Finally, we benchmark the performance of several current GenAI models/tools on various computing education datasets, and highlight the extent to which the capabilities of current models are rapidly improving.There is little doubt that LLMs and other forms of GenAI will have a profound impact on computing education over the coming years. However, just as the technology will continue to improve, so will our collective knowledge about how to leverage these new models and tools in educational settings. We expect many important conversations around this topic will emerge as the community explores how to provide more effective, inclusive, and personalised learning experiences. Our aim is that this report will serve as a focal point for both researchers and practitioners who are exploring, adapting, using, and evaluating GenAI and LLM-based tools in computing classrooms.},
booktitle = {Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {108–159},
numpages = {52},
keywords = {novice programming, llm, large language models, codex, programming, ai, curriculum, github, gpt, code generation, gpt-4, openai, pedagogical practices, llms, generative ai, copilot, cs1, computer programming, chatgpt, artificial intelligence, gpt-3},
location = {<conf-loc>, <city>Turku</city>, <country>Finland</country>, </conf-loc>},
series = {ITiCSE-WGR '23}
}

@inproceedings{08Steinhorst23,
author = {Phil Steinhorst and Andrew Petersen and Bogdan Simion and Jan Vahrenhold},
title = {Exploring Barriers in Productive Failure},
year = {2023},
isbn = {9781450399760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568813.3600111},
doi = {10.1145/3568813.3600111},
abstract = {Motivation and Objectives. Productive Failure is a problem-based learning technique where students attempt to solve a problem before receiving instruction in the topic. By design, students may not find a satisfying solution. Prior studies of Productive Failure in STEM contexts have been conducted in secondary or introductory college settings. Focusing primarily on exploring appropriate analysis and modeling techniques, these studies showed that a Productive Failure approach can lead to greater conceptual knowledge acquisition and transfer capabilities compared to »traditional«Direct Instruction techniques. In this study, we build on these studies along two dimensions: First, we report on the design and evaluation of a Productive Failure intervention in a more advanced undergraduate class: third-year Operating Systems. Second, our intervention targeted a more advanced skill: applying synchronization primitives, rather than selecting appropriate modeling and analysis techniques. Methods. We ran a quasi-experimental study in an undergraduate Operating Systems course to compare the effects of Productive Failure (PF) with Direct Instruction (DI) on students’ learning. To ensure fidelity of implementation as well as to explore different modes of instruction, we ran a pilot study in a remote learning environment. The final study was conducted in an in-person classroom environment. We collected and analyzed both qualitative and quantitative data to gather insights into the students’ problem-solving process and learning outcomes. Results. In line with previous studies, our study did not provide empirical evidence that there was any statistically significant difference with respect to reflection or short-term transfer. While we were able to verify that students in the Productive Failure condition explored a wider spectrum of solution approaches, we could not reliably detect different communication patterns across the conditions. Finally and unlike previous studies, our study was unable to detect longer-term difference in transfer capabilities. Discussion. We failed to observe several of the advantages of Productive Failure over Direct Instruction seen in prior work in other contexts. However, we note several differences in context relative to those earlier studies, including both the complexity of the topics covered and the type of intended learning outcomes. Consequently, our results do not directly contradict earlier findings. Still, they leave room for interpretation and call for further investigation of this instructional approach in more advanced computer science classes.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research V.1},
pages = {284–297},
numpages = {14},
keywords = {Operating Systems, Problem-based Learning, Productive Failure},
location = {Chicago, IL, USA},
series = {ICER '23 V1}
}

inproceedings{07Bernuy23,
author = {Angela Zavaleta Bernuy and Anna Ly and Brian Harrington and Michael Liut and Sadia Sharmin and Lisa Zhang and Andrew Petersen},
title = {"I Am Not Enough": Impostor Phenomenon Experiences of University Students},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588779},
doi = {10.1145/3587102.3588779},
abstract = {Recent work has confirmed that computing students experience the Imposter Phenomenon (IP) at higher rates than reported in other disciplines. However, no work has examined what aspects of the university computing experience might lead to a higher rate of IP experiences. We aim to illustrate the IP experiences students have, identify common sources of these experiences, and document the effects of these experiences and how students respond to them. We asked undergraduate students to share recent experiences that illustrate their experiences with the IP. We conducted an inductive thematic analysis on these open-ended responses, resulting in a set of inter-connected themes. A significant fraction of students related stories about making comparisons with peers or observing peer behaviour that made them question their abilities. Students also spoke about holding unrealistic expectations learned from their peers or imposed by the environment. These experiences may be particularly acute for minority-affiliated students who may come to feel they do not belong. Ultimately, these IP experiences can lead to a loss of motivation or a cycle of failure that leads students to leave computing. The central role social comparisons play in IP experiences suggests that it is particularly important to foster communities where opportunities for comparison are reduced and where realistic expectations are explicitly set.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {313–319},
numpages = {7},
keywords = {impostor phenomenon, qualitative, IP, survey},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

inproceedings{07Sibia23,
author = {Naaz Sibia and Angela Zavaleta Bernuy and Joseph Jay Williams and Michael Liut and Andrew Petersen},
title = {Student Usage of Q\&A Forums: Signs of Discomfort?},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588842},
doi = {10.1145/3587102.3588842},
abstract = {Q\&A forums are widely used in large classes to provide scalable support. In addition to offering students a space to ask questions, these forums aim to create a community and promote engagement. Prior literature suggests that the way students participate in Q\&A forums varies and that most students do not actively post questions or engage in discussions. Students may display different participation behaviours depending on their comfort levels in the class. This paper investigates students' use of a Q\&A forum in a CS1 course. We also analyze student opinions about the forum to explain the observed behaviour, focusing on students' lack of visible participation (lurking, anonymity, private posting). We analyzed forum data collected in a CS1 course across two consecutive years and invited students to complete a survey about perspectives on their forum usage. Despite a small cohort of highly engaged students, we confirmed that most students do not actively read or post on the forum. We discuss students' reasons for the low level of engagement and barriers to participating visibly. Common reasons include fearing a lack of knowledge and repercussions from being visible to the student community.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {33–39},
numpages = {7},
keywords = {confidence, Q\&A forums, gender, anonymity},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@InProceedings{07Petersen23,
author = {Brandon Jaipersaud and Paul Zhang and Jimmy Ba and Andrew Petersen and Lisa Zhang and Michael R. Zhang},
editor="Wang, Ning
and Rebolledo-Mendez, Genaro
and Dimitrova, Vania
and Matsuda, Noboru
and Santos, Olga C.",
title="Decomposed Prompting to Answer Questions on a Course Discussion Board",
booktitle="Artificial Intelligence in Education",
year="2023",
publisher="Springer Nature Switzerland",
address="Cham",
pages="218--223",
abstract="We propose and evaluate a question-answering system that uses decomposed prompting to classify and answer student questions on a course discussion board. Our system uses a large language model (LLM) to classify questions into one of four types: conceptual, homework, logistics, and not answerable. This enables us to employ a different strategy for answering questions that fall under different types. Using a variant of GPT-3, we achieve 81{\%} classification accuracy. We discuss our system's performance on answering conceptual questions from a machine learning course and various failure modes.",
isbn="978-3-031-36336-8",
url = {https://doi.org/10.1007/978-3-031-36336-8_33}
}

inproceedings{03Zhang23,
author = {Lisa Zhang and Bogdan Simion and Michael Kaler and Amna Liaqat and Daniel Dick and Andi Bergen and Michael Miljanovic and Andrew Petersen},
title = {Embedding and Scaling Writing Instruction Across First- and Second-Year Computer Science Courses},
year = {2023},
isbn = {9781450394314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545945.3569729},
doi = {10.1145/3545945.3569729},
abstract = {Writing skills are often considered unimportant by computer science students and were under-emphasized in our curriculum. We describe our experience embedding CS-specific writing instruction at scale in most of our large, core, first- and second-year Computer Science courses, each with 300-800+ students. Our approach is to collaborate with a writing specialist and a community of course instructors, centralize the management of writing teaching assistants, and introduce a variety of relevant genres and contexts to help students develop and apply writing skills. We outline the institutional support and organization crucial to a project of this scale. In addition, we report on a survey collecting student perception of the writing instruction/assessment. We reflect on quantitative and qualitative evidence of success, as well as the challenges that we faced. We believe that many of these challenges will be common across institutions, parti
cularly those with large courses.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
pages = {610–616},
numpages = {7},
keywords = {wid, wac, wtl, written communication, cs education},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

inproceedings{03Bui23,
author = {Giang Bui and Naaz Sibia and Angela Zavaleta Bernuy and Michael Liut and Andrew Petersen},
title = {Prior Programming Experience: A Persistent Performance Gap in CS1 and CS2},
year = {2023},
isbn = {9781450394314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545945.3569752},
doi = {10.1145/3545945.3569752},
abstract = {Previous work has reported on the advantageous effects of prior experience in CS1, but it remains unclear whether these effects fade over a sequence of introductory programming courses. Furthermore, while student perceptions suggest that prior experience remains important, studies have reported that a student's expectation of their performance is a more accurate predictor of outcome. We aim to confirm if prior experience (formal or informal) provides short-term and long-term advantages in computing courses or if the advantage fades. Furthermore, we explore whether the expectation of performance is a more accurate predictor of student success than informal and formal prior experience. To explore these questions, we deployed surveys in a CS1 course to gauge students' level of prior experience in programming, prediction of final exam grades, and self-efficacy to succeed in university. Grades from CS1 and CS2 were also collected. We observed a persistent (1-letter grade) gap between the performance of students with no prior experience and those with any experience, but we did not observe a noteworthy gap when comparing student performance based on formal or informal experience. We also observed differences in self-efficacy and retention rates between different levels of prior experience. Lastly, we confirm that success in CS1 can be better reflected and predicted by some controllable factors, such as students' perceptions of ability.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
pages = {889–895},
numpages = {7},
keywords = {cs2, prior experience, self-efficacy, confidence, cs1, prediction},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{12Petersen22,
author = {Johan Jeuring and Hieke Keuning and Samiha Marwan and Dennis Bouvier and Cruz Izu and Natalie Kiesler and Teemu Lehtinen and Dominic Lohr and Andrew Peterson and Sami Sarsa},
title = {Towards Giving Timely Formative Feedback and Hints to Novice Programmers},
year = {2022},
isbn = {9798400700101},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3571785.3574124},
doi = {10.1145/3571785.3574124},
abstract = {Every year, millions of students learn how to write programs. Learning activities for beginners almost always include programming tasks that require a student to write a program to solve a particular problem. When learning how to solve such a task, many students need feedback on their previous actions, and hints on how to proceed. For tasks such as programming, which are most often solved stepwise, the feedback should take the steps a student has taken towards implementing a solution into account, and the hints should help a student to complete or improve a possibly partial solution. This paper investigates how previous research on feedback is translated to when and how to give feedback and hints on steps a student takes when solving a programming task. We have selected datasets consisting of sequences of steps students take when working on a programming problem, and annotated these datasets at those places at which experts would intervene, and how they would intervene. We have used these datasets to compare expert feedback and hints to feedback and hints given by learning environments for programming. Although we have constructed extensive guidelines on when and how to give feedback, we observed plenty of disagreement between experts. We also found several differences between feedback given by experts and learning environments. Experts intervene at specific moments, while in learning environments students have to ask for feedback themselves. The contents of feedback is also different; experts often give (positive) feedback on subgoals, which is not supported by most environments.},
booktitle = {Proceedings of the 2022 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {95–115},
numpages = {21},
keywords = {sequences of programming steps, feedback and hints, learning environments, automated feedback, learning programming},
location = {Dublin, Ireland},
series = {ITiCSE-WGR '22}
}

@inproceedings{03Bernuy22,
author = {Angela Zavaleta Bernuy and Ziwen Han and Hammad Shaikh and Qi Yin Zheng and Lisa-Angelique Lim and Anna Rafferty and Andrew Petersen and Joseph Jay Williams},
title = {How Can Email Interventions Increase Students’ Completion of Online Homework? A Case Study Using A/B Comparisons},
year = {2022},
isbn = {9781450395731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3506860.3506874},
doi = {10.1145/3506860.3506874},
abstract = {Email communication between instructors and students is ubiquitous, and it could be valuable to explore ways of testing out how to make email messages more impactful. This paper explores the design space of using emails to get students to plan and reflect on starting weekly homework earlier. We deployed a series of email reminders using randomized A/B comparisons to test alternative factors in the design of these emails, providing examples of an experimental paradigm and metrics for a broader range of interventions. We also surveyed and interviewed instructors and students to compare their predictions about the effectiveness of the reminders with their actual impact. We present our results on which seemingly obvious predictions about effective emails are not borne out, despite there being evidence for further exploring these interventions, as they can sometimes motivate students to attempt their homework more often. We also present qualitative evidence about student opinions and behaviours after receiving the emails, to guide further interventions. These findings provide insight into how to use randomized A/B comparisons in everyday channels such as emails, to provide empirical evidence to test our beliefs about the effectiveness of alternative design choices. },
booktitle = {LAK22: 12th International Learning Analytics and Knowledge Conference},
pages = {107–118},
numpages = {12},
keywords = {Randomized experiments, Reminder, Embedded experimentation, Procrastination, A/B comparisons},
location = {Online, USA},
series = {LAK22}
}

inproceedings{03Harrington22,
author = {Angela Zavaleta Bernuy and Anna Ly and Brian Harrington and Michael Liut and Andrew Petersen and Sadia Sharmin and Lisa Zhang},
title = {Additional Evidence for the Prevalence of the Impostor Phenomenon in Computing},
year = {2022},
isbn = {9781450390705},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3478431.3499282},
doi = {10.1145/3478431.3499282},
abstract = {Motivation Despite the widespread belief that computing practitioners frequently experience the Imposter Phenomenon (IP), little formal work has measured the prevalence of IP in the computing community despite its negative effect on achievement.Objectives This study aims to replicate recent work that has suggested that IP experiences are widespread in computing students and to extend that work by exploring the relationship between the IP, progress in the program, and ethnic identity.Methods A survey with several demographic questions (gender, ethnicity, international status, and year of study) and Clance's IP scale (CIPS) was deployed to students in post-secondary computing courses. Correlations between demographic factors and CIPS scores were evaluated, and a linear model was constructed to explore the interaction between demographic factors of interest.Results We reaffirm that a high proportion of CS students meet the IP diagnostic criteria and that women report higher CIPS scores than men. We also present evidence that Asian students with domestic and international status report different levels of IP experiences.Discussion These findings highlight the importance – to educators at all levels – of cultivating belonging in computing communities.},
booktitle = {Proceedings of the 53rd ACM Technical Symposium on Computer Science Education},
pages = {654–660},
numpages = {7},
keywords = {imposter syndrome, impostor phenomenon, belonging},
location = {Providence, RI, USA},
series = {SIGCSE 2022}
}

inproceedings{11ly21,
author = {Anna Ly and Jack Parkinson and Quintin Cutts and Michael Liut and Andrew Petersen},
title = {Spatial Skills and Demographic Factors in CS1},
year = {2021},
isbn = {9781450384889},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3488042.3488049},
doi = {10.1145/3488042.3488049},
abstract = {Motivation Prior studies have established that training spatial skills may improve outcomes in computing courses. Very few of these studies have, however, explored the impact of spatial skills training on women or examined its relationship with other factors commonly explored in the context of academic performance, such as socioeconomic background and self-efficacy. Objectives In this study, we report on a spatial skills intervention deployed in a computer programming course (CS1) in the first year of a post-secondary program. We explore the relationship between various demographic factors, course performance, and spatial skills ability at both the beginning and end of the term. Methods Data was collected using a combination of demographic surveys, existing self-efficacy and CS1 content instruments, and the Revised PVST:R spatial skills assessment. Spatial skills were evaluated both at the beginning of the term and at the end, after spatial skills training was provided. Results While little evidence was found to link spatial skills to socioeconomic status or self-efficacy, both gender identity and previous experience in computing were found to be correlated to spatial skills ability at the start of the course. Women initially recorded lower spatial skills ability, but after training, the distribution of spatial skills scores for women approached that of men. Discussion These findings suggest that, if offered early enough, spatial skills training may be able to remedy some differences in background that impact performance in computing courses. },
booktitle = {21st Koli Calling International Conference on Computing Education Research},
articleno = {4},
numpages = {10},
keywords = {retention, spatial skills, socioeconomic status, CS1, gender},
location = {Joensuu, Finland},
series = {Koli Calling '21}
}

article{12parkinson21,
author = {Jack Parkinson and Ryan Bockmon and Quintin Cutts and Michael Liut and Andrew Petersen and Sheryl Sorby},
title = {Practice Report: Six Studies of Spatial Skills Training in Introductory Computer Science},
year = {2021},
issue_date = {December 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {4},
issn = {2153-2184},
url = {https://doi.org/10.1145/3494574},
doi = {10.1145/3494574},
journal = {ACM Inroads},
month = {nov},
pages = {18–29},
numpages = {12}
}

inproceedings{ly2021revisiting,
  title={Revisiting Syntax Exercises in CS1},
  author = {Anna Ly and John Edwards and Michael Liut and Andrew Petersen},
  booktitle={Proceedings of the 22st Annual Conference on Information Technology Education},
  pages={9--14},
  year={2021},
  url = {https://doi.org/10.1145/3450329.3476855},
  doi = {10.1145/3450329.3476855},
}

@InProceedings{06Zavaleta21,
author = {Angela Zavaleta-Bernuy and Qi Yin Zheng and Hammad Shaikh and Jacob Nogas and Anna Rafferty and Andrew Petersen and Joseph Jay Williams},
editor="Roll, Ido
and McNamara, Danielle
and Sosnovsky, Sergey
and Luckin, Rose
and Dimitrova, Vania",
title="Using Adaptive Experiments to Rapidly Help Students",
booktitle="Artificial Intelligence in Education",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="422--426",
abstract="Adaptive experiments can increase the chance that current students obtain better outcomes from a field experiment of an instructional intervention. In such experiments, the probability of assigning students to conditions changes while more data is being collected, so students can be assigned to interventions that are likely to perform better. Digital educational environments lower the barrier to conducting such adaptive experiments, but they are rarely applied in education. One reason might be that researchers have access to few real-world case studies that illustrate the advantages and disadvantages of these experiments in a specific context. We evaluate the effect of homework email reminders in students by conducting an adaptive experiment using the Thompson Sampling algorithm and compare it to a traditional uniform random experiment. We present this as a case study on how to conduct such experiments, and we raise a range of open questions about the conditions under which adaptive randomized experiments may be more or less useful.",
isbn="978-3-030-78270-2",
url={https://link.springer.com/chapter/10.1007/978-3-030-78270-2_75},
doi={10.1007/978-3-030-78270-2_75}
}

@inproceedings{06Asano21,
author = {Yuya Asano and Madhurima Dutta and Trisha Thakur and Jaemarie Solyst and Stephanie Cristea and Helena Jovic and Andrew Petersen and Joseph Jay Williams},
title = {Exploring Additional Personalized Support While Attempting Exercise Problems in Online Learning Platforms},
year = {2021},
isbn = {9781450382151},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3430895.3460145},
doi = {10.1145/3430895.3460145},
abstract = {In online asynchronous learning environments, students are assigned exercises, but it is not clear how to incorporate the kinds of actions an in-person tutor might take such as explaining, providing more practice, prompting for reflection, and motivating. We explore approaches to adding "Drop-Downs'' that appear after a student submits an answer and that contain additional information to support learning. We conducted randomized A/B experiments exploring the impact of these Drop-Downs on student learning in the online portion of a flipped CS1 course. The deployed Drop-Downs in this course provided explanations, reflective prompts, additional problems, and motivational messages. The results suggest that students benefit from various Drop-Downs in different contexts, indicating the possibility of personalizing content based on the student's state. We discuss the resulting design implications of Drop-Downs in online learning systems.},
booktitle = {Proceedings of the Eighth ACM Conference on Learning @ Scale},
pages = {235–238},
numpages = {4},
keywords = {field deployment, online learning, A/B testing, intervention, randomized experiments, personalization},
location = {Virtual Event, Germany},
series = {L@S '21}
}

@inproceedings{03Petersen21-2,
author = {Angela Zavaleta Bernuy and Qi Yin Zheng and Hammad Shaikh and Andrew Petersen and Joseph Jay Williams},
title = {Investigating the Impact of Online Homework Reminders Using Randomized A/B Comparisons},
year = {2021},
isbn = {9781450380621},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3408877.3432427},
doi = {10.1145/3408877.3432427},
abstract = {Procrastination by students may lead to adverse outcomes such as a focus on completion rather than learning or even a failure to complete learning tasks. One common method for motivating students and reducing procrastination is to send reminders with hints and study strategies, but it's not clear if these messages are effective or when is the best time to send them. Randomized A/B comparisons could be used to try different reminders or alternative ideas about how best to get students to start work earlier and, crucially, to measure the impact of these interventions on behaviour. This paper describes an A/B comparison of reminder emails set in a large CS1 course at a research-focused North American u
niversity. We found evidence that the email interventions caused a higher proportion of students to attempt the online h
omework but did not see evidence that these particular emails got students to start early, irrespective of changes to the timing of the reminder. More broadly, these findings illustrate how to use A/B comparisons in educational settings to test ideas about how to help students, and demonstrate the value of using randomized A/B comparisons, even when evaluating actions that seem obviously beneficial, such as reminder emails.},
booktitle = {Proceedings of the 52nd ACM Technical Symposium on Computer Science Education},
pages = {921–927},
numpages = {7},
keywords = {A/B comparisons, procrastination, reminders, CS1, email},
location = {Virtual Event, USA},
series = {SIGCSE '21}
}

@inproceedings{03Petersen21,
author = {Jaemarie Solyst and Trisha Thakur and Madhurima Dutta and Yuya Asano and Andrew Petersen and Joseph Jay Williams},
title = {Procrastination and Gaming in an Online Homework System of an Inverted CS1},
year = {2021},
isbn = {9781450380621},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3408877.3432440},
doi = {10.1145/3408877.3432440},
abstract = {Engaged preparation and study in combination with lectures are important for all courses but are particularly critical for online, hybrid, and inverted classrooms. Many instructors use online systems to deliver new course content and exercises, but students often delay assignments or game these systems (e.g., guessing on multiple-choice questions), often to the detriment of their learning. In an inverted CS1 course, many students self-reported high rates of gaming-the-system behavior, so we examine survey data to identify factors that contribute to engagement in these maladaptive behaviours. We supplement that analysis with interview data to gain a deeper understanding of the situation. We also implemented and evaluated a previously reported online intervention aimed at reducing gaming behavior. Unlike prior work, our intervention did not have a significant effect on guessing behavior. We discuss why the factors we identified might explain this result, as well as suggest future work to improve our understanding of gaming behaviours and inform the design of systems that encourage effective learning.},
booktitle = {Proceedings of the 52nd ACM Technical Symposium on Computer Science Education},
pages = {789–795},
numpages = {7},
keywords = {online learning, inverted classroom, gaming the system, procrastination},
location = {Virtual Event, USA},
series = {SIGCSE '21}
}

inproceedings{03Zhang21,
author = {Larry Yueli Zhang and Andrew K. Petersen and Michael Liut and Bogdan Simion and Furkan Alaca},
title = {A Multi-Course Report on the Experience of Unplanned Online Exams},
year = {2021},
isbn = {9781450380621},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3408877.3432515},
doi = {10.1145/3408877.3432515},
abstract = {We report our experience of preparing and conducting unplanned online exams in the unique half-physical, half-virtual semester of Winter 2020. The report covers four courses in a large university's computer science program, ranging from first-year to third-year. With the data generated by students taking both in-person and online exams in multiple courses, we perform analyses to evaluate the validity of the online exams (especially the unproctored ones) as an assessment of student understanding. With the fine-grained student activity data provided by the online exam platform, we are also able to investigate the patterns in student exam-taking behaviours and their correlations with student performance on the exam. In addition, we share, in detail, the tips and lessons that were learned throughout the process of designing, implementing, and hosting the online exams.},
booktitle = {Proceedings of the 52nd ACM Technical Symposium on Computer Science Education},
pages = {17–23},
numpages = {7},
keywords = {student behaviour, online exams, assessment},
location = {Virtual Event, USA},
series = {SIGCSE '21}
}

@inproceedings{06Petersen20-2,
author = {Sally Fincher and Johan Jeuring and Craig S. Miller and Peter Donaldson and Benedict du Boulay and Matthias Hauswirth and Arto Hellas and Felienne Hermans and Colleen Lewis and Andreas M\"{u}hling and Janice L. Pearce and Andrew Petersen}{u}hling and Janice L. Pearce and Andrew Petersen},
title = {Notional Machines in Computing Education: The Education of Attention},
year = {2020},
isbn = {9781450382939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3437800.3439202},
doi = {10.1145/3437800.3439202},
abstract = {This report defines notional machines (NMs), and provides a series of definitional characteristics by which they may be identified. Over several sections, it includes a first-hand report of the origin of NMs, reports a systematic literature review to track the use and development of the concept, and presents a small collection of examples collected through interviews with experienced teachers. Additionally, the report presents NMs in a common format, and makes some preliminary explorations of their use in practice, including examples of instructors using multiple NMs in sequence. Approach and method are fully detailed in evidential appendices, to support replication of results and adoption/adaptation of practice.},
booktitle = {Proceedings of the Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {21–50},
numpages = {30},
keywords = {notional machines, computing education},
location = {Trondheim, Norway},
series = {ITiCSE-WGR '20}
}

@inproceedings{11Petersen20,
author = {Jacqueline Whalley and Andrew Petersen and Paul Denny},
title = {Mathematics, Computer Science and Career Inclinations — A Multi-Institutional Exploration},
year = {2020},
isbn = {9781450389211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3428029.3428046},
doi = {10.1145/3428029.3428046},
abstract = {Mathematics is at the heart of computer science as a discipline, yet not all students appreciate the relevance and importance of mathematics in a computing degree. Recent work presented a hypothesis that a student’s career inclinations may impact their view towards the value of learning mathematics, and thus their course selections. However, empirical support for this theory has previously been limited to a single institution in which students are required to include mathematics as part of their degree. In this work, we conduct a replication study in a different institutional context where mathematics is not a strict requirement for computer science students. We find robust support for the previously hypothesized relationship between career inclinations and perceptions of mathematics, and a strongly stated desire from students that the mathematics they learn should be more clearly connected and relevant to computer science. },
booktitle = {Koli Calling '20: Proceedings of the 20th Koli Calling International Conference on Computing Education Research},
articleno = {17},
numpages = {10},
keywords = {factor analysis, careers, mathematics, curriculum, identity},
location = {Koli, Finland},
series = {Koli Calling '20}
}

@inproceedings{08Steinhorst20,
  author = {Phil Steinhorst and Andrew Petersen and Jan Vahrenhold},
title = {Revisiting Self-Efficacy in Introductory Programming},
year = {2020},
isbn = {9781450370929},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3372782.3406281},
doi = {10.1145/3372782.3406281},
booktitle = {Proceedings of the 2020 ACM Conference on International Computing Education Research},
pages = {158–169},
numpages = {12},
keywords = {factor analysis, introductory programming, self-efficacy},
location = {Virtual Event, New Zealand},
series = {ICER ’20}
}
  
@inproceedings{07Prystawski20,
 author = {Ben Prystawski and Jacob Nogas and Andrew Petersen and Joseph Williams},
 title = {Effects of Explanations and Additional Practice on Short versus Long Term Learning in Online Programming Homework},
 booktitle = {Educational Data Mining in Computer Science Education (CSEDM) Workshop @ EDM},
 year = {2020},
 numpage = {6},
 url = {https://drive.google.com/file/d/1SNTCvsRy-1YRSAXo1UYFu2IjKIK-CphN/view?usp=sharing},
}

@inproceedings{06Petersen20,
 title = {ProgSnap2: A Flexible Format for Programming Process Data},
 author = {Thomas Price and David Hovemeyer and Kelly Rivers and Austin Bart and Ge Gao and Ayaan M. Kazerouni and Brett Becker and Andrew Petersen and Luke Gusukuma and Stephen H. Edwards and David Babcock},
year = {2020},
isbn = {9781450368742},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341525.3387373},
doi = {10.1145/3341525.3387373},
booktitle = {Proceedings of the 2020 ACM Conference on Innovation and Technology in Computer Science Education},
pages = {356–362},
numpages = {7},
keywords = {programming process data, compiler error metrics, data sharing},
location = {Trondheim, Norway},
series = {ITiCSE ’20}
}
  
@inproceedings{12Szabo19,
author = {Claudia Szabo and Nickolas Falkner and Andrew Petersen and Heather Bort and Kathryn Cunningham and Peter Donaldson and Arto Hellas and James Robinson and Judy Sheard},
title = {Review and Use of Learning Theories within Computer Science Education Research: Primer for Researchers and Practitioners},
year = {2019},
isbn = {9781450375672},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3344429.3372504},
doi = {10.1145/3344429.3372504},
booktitle = {Proceedings of the Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {89–109},
numpages = {21},
keywords = {computing education, epistemology, learning theory},
location = {Aberdeen, Scotland Uk},
series = {ITiCSE-WGR ’19}
}
  
inproceedings{05Campbell19,
 author = {Jennifer Campbell and Michelle Craig and Andrew Petersen},
 title = {Answering the Correct Question},
 booktitle = {Proceedings of the ACM Conference on Global Computing Education},
 series = {CompEd '19},
 year = {2019},
 isbn = {978-1-4503-6259-7},
 location = {Chengdu,Sichuan, China},
 pages = {72--77},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/3300115.3309529},
 doi = {10.1145/3300115.3309529},
 acmid = {3309529},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@inproceedings{04Petersen19,
 author = {Thomas Price and David Hovemeyer and Kelly Rivers and Austin Cory Bart and Andrew Petersen and Brett Becker and Jason Lefever},
 title = {ProgSnap 2: A Flexible Format for Programming Snapshot Data},
 booktitle = {Proceedings of the 2nd Educational Data Mining in Computer Science Education Workshop},
 url = {https://people.engr.ncsu.edu/twprice/website/files/CSEDM%202019%20ProgSnap2.pdf},
 year = {2019},
}

@inproceedings{03Petersen19,
 author = {Nikki Sigurdson and Andrew Petersen},
 title = {A Survey-based Exploration of Computer Science Student Perspectives on Mathematics},
 booktitle = {Proceedings of the 50th ACM Technical Symposium on Computer Science Education},
 series = {SIGCSE '19},
 year = {2019},
 isbn = {978-1-4503-5890-3},
 location = {Minneapolis, MN, USA},
 pages = {1032--1038},
 numpages = {7},
 url = {http://doi.acm.org/10.1145/3287324.3287416},
 doi = {10.1145/3287324.3287416},
 acmid = {3287416},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {identity, mathematics},
} 

inproceedings{03Liu19,
 author = {David Liu and Andrew Petersen},
 title = {Static Analyses in Python Programming Courses},
 booktitle = {Proceedings of the 50th ACM Technical Symposium on Computer Science Education},
 series = {SIGCSE '19},
 year = {2019},
 isbn = {978-1-4503-5890-3},
 location = {Minneapolis, MN, USA},
 pages = {666--671},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/3287324.3287503},
 doi = {10.1145/3287324.3287503},
 acmid = {3287503},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {cs1, error messages, errors, python, static analysis},
} 

inproceedings{03Campbell19,
 author = {Jennifer Campbell and Jacqueline Smith and Andrew Petersen}, 
 title = {Self-paced Mastery Learning CS1},
 booktitle = {Proceedings of the 50th ACM Technical Symposium on Computer Science Education},
 series = {SIGCSE '19},
 year = {2019},
 isbn = {978-1-4503-5890-3},
 location = {Minneapolis, MN, USA},
 pages = {955--961},
 numpages = {7},
 url = {http://doi.acm.org/10.1145/3287324.3287481},
 doi = {10.1145/3287324.3287481},
 acmid = {3287481},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {cs1, mastery learning, novice programming, self-paced},
} 

@inproceedings{12Hellas18,
 author = {Arto Hellas and Petri Ihantola and Andrew Petersen and Vangel V. Ajanovski and Mirela Gutica and Timo Hynninen and Antti Knutas and Juho Leinonen and Chris Messom and Soohyun Nam Liao},
 title = {Predicting Academic Performance: A Systematic Literature Review},
 booktitle = {Proceedings Companion of the 23rd Annual ACM Conference on Innovation and Technology in Computer Science Education},
 series = {ITiCSE 2018 Companion},
 year = {2018},
 isbn = {978-1-4503-6223-8},
 location = {Larnaca, Cyprus},
 pages = {175--199},
 numpages = {25},
 url = {http://doi.acm.org/10.1145/3293881.3295783},
 doi = {10.1145/3293881.3295783},
 acmid = {3295783},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {analytics, educational data mining, learning analytics, literature review, mapping study, performance, prediction},
} 

@inproceedings{01Ihantola19,
 title = {Code Complexity in Introductory Programming Courses},
 author = {Petri Ihantola and Andrew Petersen},
 booktitle = {Proceedings of the 52nd Annual Hawaii International Conference on System Sciences},
 series = {HICCS-52},
 year = {2019},
 numpages = {6},
 publisher = {Computer Society Press},
 url = {https://scholarspace.manoa.hawaii.edu/handle/10125/60204},
}

@inproceedings{11Petersen18-1,
 author = {Nikki Sigurdson and Andrew Petersen},
 title = {An Exploration of Grit in a {CS1} Context},
 booktitle = {Proceedings of the 18th Koli Calling International Conference on Computing Education Research},
 series = {Koli Calling '18},
 year = {2018},
 location = {Koli, Finland},
 isbn = {978-1-4503-6535-2},
 location = {Koli, Finland},
 pages = {23:1--23:5},
 articleno = {23},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/3279720.3279743},
 doi = {10.1145/3279720.3279743},
 acmid = {3279743},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {CS1, grit, learning analytics, psychometric factors},
} 

@inproceedings{11Petersen18-2,
 author = {Roya Hosseini, Kamil Akhusyinoglu, Andrew Petersen, Christian D. Schunn, and Peter Brusilovsky},
 title = {{PCEX}: Interactive Program Construction Examples for Learning Programming},
 booktitle = {Proceedings of the 18th Koli Calling International Conference on Computing Education Research},
 series = {Koli Calling '18},
 year = {2018},
 location = {Koli, Finland},
 isbn = {978-1-4503-6535-2},
 pages = {5:1--5:9},
 articleno = {5},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/3279720.3279726},
 doi = {10.1145/3279720.3279726},
 acmid = {3279726},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {CS1, Java programming, computer science education, interactive learning technologies, worked examples},
} 

@inproceedings{07Petersen18-2, 
 title = {A Multi-institution Exploration of Peer Instruction in Practice},
 author = {Cynthia Taylor and Jaime Spacco and David P. Bunde and Andrew Petersen and Soohyun Nam Liao and Leo Porter},
 booktitle = {Proceedings of the 23rd Annual ACM Conference on Innovation and Technology in Computer Science Education},
 series = {ITiCSE 2018},
 year = {2018},
 isbn = {978-1-4503-5707-4},
 location = {Larnaca, Cyprus},
 pages = {308--313},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/3197091.3197144},
 doi = {10.1145/3197091.3197144},
 acmid = {3197144},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Active Learning, CS Education, Clicker Questions, Peer Instruction},
}

@inproceedings{07Petersen18-1,
 title = {Code Reviews in Large, First Year Courses},
 author = {Andrew Petersen and Dan Zingaro},
 booktitle = {Proceedings of the 23rd Annual ACM Conference on Innovation and Technology in Computer Science Education},
 series = {ITiCSE 2018},
 year = {2018},
 isbn = {978-1-4503-5707-4},
 location = {Larnaca, Cyprus},
 pages = {354--355},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/3197091.3205832},
 doi = {10.1145/3197091.3205832},
 acmid = {3205832},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {CS1, code review, peer review, studio-based learning},
} 

inproceedings{07Denny18,
 title = {Improving Complex Task Performance Using a Sequence of Simple Practice Tasks},
 author = {Paul Denny and Andrew Luxton-Reilly and Michelle Craig and Andrew Petersen},
 booktitle = {Proceedings of the 23rd Annual ACM Conference on Innovation and Technology in Computer Science Education},
 series = {ITiCSE 2018},
 year = {2018},
 isbn = {978-1-4503-5707-4},
 location = {Larnaca, Cyprus},
 pages = {4--9},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/3197091.3197141},
 doi = {10.1145/3197091.3197141},
 acmid = {3197141},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {CS1, assessment, compound assessment, novice programming},
 comment = {<b>Best Paper finalist (top 3).</b>},
}

@inproceedings{04Petersen:2018,
 author = {Paul Denny and Fiona McDonald and Ruth Empson and Philip Kelly and Andrew Petersen},
 title = {Empirical Support for a Causal Relationship Between Gamification and Learning Outcomes},
 booktitle = {Proceedings of the 2018 {CHI} Conference on Human Factors in Computing Systems},
 series = {CHI '18},
 year = {2018},
 isbn = {978-1-4503-5620-6},
 location = {Montreal QC, Canada},
 pages = {311:1--311:13},
 articleno = {311},
 numpages = {13},
 url = {http://doi.acm.org/10.1145/3173574.3173885},
 doi = {10.1145/3173574.3173885},
 acmid = {3173885},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {badges, gamification, peerwise, points, self-testing},
 comment={<b>Honorable Mention (Top 5%).</b>},
} 

@inproceedings{01Simon18,
 author = {Simon and Judy Sheard and Michael Morgan and Andrew Petersen and Amber Settle and Jane Sinclair},
 title = {Informing Students about Academic Integrity in Programming},
 booktitle = {Proceedings of the 20th Australasian Computing Education Conference},
 series = {ACE '18},
 year = {2018},
 isbn = {978-1-4503-6340-2},
 location = {Brisbane, Queensland, Australia},
 pages = {113--122},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/3160489.3160502},
 doi = {10.1145/3160489.3160502},
 acmid = {3160502},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {academic integrity, collusion, computing education, plagiarism, programming education},
}

inproceedings{11Craig17,
 author = {Michelle Craig and Jacqueline Smith and Andrew Petersen},
 title = {Familiar Contexts and the Difficulty of Programming Problems},
 booktitle = {Proceedings of the 17th Koli Calling Conference on Computing Education Research},
 series = {Koli Calling '17},
 year = {2017},
 isbn = {978-1-4503-5301-4},
 location = {Koli, Finland},
 pages = {123--127},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/3141880.3141898},
 doi = {10.1145/3141880.3141898},
 acmid = {3141898},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {CS1, context, novice programmers, transfer},
} 

@inproceedings{11Sigurdson17,
 author = {Nikki Sigurdson and Andrew Petersen},
 title = {Student Perspectives on Mathematics in Computer Science},
 booktitle = {Proceedings of the 17th Koli Calling Conference on Computing Education Research},
 series = {Koli Calling '17},
 year = {2017},
 isbn = {978-1-4503-5301-4},
 location = {Koli, Finland},
 pages = {108--117},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/3141880.3141888},
 doi = {10.1145/3141880.3141888},
 acmid = {3141888},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {curriculum, identity, mathematics},
} 

@inproceedings{08Luxton-Reilly17,
 author = {Andrew Luxton-Reilly and Brett A. Becker and Yingjun Cao and Roger McDermott and Claudio Mirolo and Andreas M\"{u}hling and Andrew Petersen and Kate Sanders and Simon and Jacqueline Whalley}{u}hling and Andrew Petersen and Kate Sanders and Simon and Jacqueline Whalley},
 title = {Developing Assessments to Determine Mastery of Programming Fundamentals},
 booktitle = {Proceedings of the 2017 ITiCSE Conference on Working Group Reports},
 series = {ITiCSE-WGR '17},
 year = {2017},
 isbn = {978-1-4503-5627-5},
 location = {Bologna, Italy},
 pages = {47--69},
 numpages = {23},
 url = {http://doi.acm.org/10.1145/3174781.3174784},
 doi = {10.1145/3174781.3174784},
 acmid = {3174784},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {assessment, compound assessment, concept inventory, cs1, exam, introductory programming, iticse working group, learning, learning objectives, learning outcomes, mastery, novice programming, questions},
} 

@inproceedings{07Denny17,
 author = {Paul Denny and Ewan Tempero and Dawn Garbett and Andrew Petersen},
 title = {Examining a Student-Generated Question Activity Using Random Topic Assignment},
 booktitle = {Proceedings of the 2017 {ACM} Conference on Innovation and Technology in Computer Science Education},
 series = {ITICSE '17},
 year = {2017},
 location = {Bologna, Italy},
 numpages = {6},
 url = {https://doi.org/10.1145/3059009.3059033},
 doi = {10.1145/3059009.3059033},
 pages = {146--151},
 publisher = {ACM},
 address = {New York, NY, USA},
}

inproceedings{03Hovemeyer:2017,
 author = {David Hovemeyer and Arto Hellas and Andrew Petersen and Jaime Spacco},
 title = {Progsnap: Sharing Programming Snapshots for Research (Abstract Only)},
 booktitle = {Proceedings of the 2017 ACM SIGCSE Technical Symposium on Computer Science Education},
 series = {SIGCSE '17},
 year = {2017},
 isbn = {978-1-4503-4698-6},
 location = {Seattle, Washington, USA},
 pages = {709--709},
 numpages = {1},
 url = {http://doi.acm.org/10.1145/3017680.3022418},
 doi = {10.1145/3017680.3022418},
 acmid = {3022418},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {educational data mining, learning analytics, programming snapshots},
} 

@inproceedings{03Castro-WunschA17,
 author = {Karo Castro-Wunsch and Alireza Ahadi and Andrew Petersen},
 title = {Evaluating Neural Networks As a Method for Identifying Students in Need of Assistance},
 booktitle = {Proceedings of the 2017 ACM SIGCSE Technical Symposium on Computer Science Education},
 series = {SIGCSE '17},
 year = {2017},
 isbn = {978-1-4503-4698-6},
 location = {Seattle, Washington, USA},
 pages = {111--116},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/3017680.3017792},
 doi = {10.1145/3017680.3017792},
 acmid = {3017792},
 keywords = {CS1, at-risk students, educational data mining, introductory programming, learning analytics, replication, reproduction, source code snapshot analysis},
 comment = {<b>Recognized as a SIGCSE Exemplary (Top 25%) Paper</b>},
} 

@inproceedings{06SimonS16,
 author = {Simon and Judy Sheard and Michael Morgan and Andrew Petersen and Amber Settle and Jane Sinclair and Gerry Cross and Charles Riedesel},
 title = {Negotiating the Maze of Academic Integrity in Computing Education},
 booktitle = {Proceedings of the 2016 {ITiCSE} Working Group Reports},
 series = {ITiCSE '16},
 year = {2016},
 isbn = {978-1-4503-4882-9},
 location = {Arequipa, Peru},
 pages = {57--80},
 numpages = {24},
 url = {http://doi.acm.org/10.1145/3024906.3024910},
 doi = {10.1145/3024906.3024910},
 acmid = {3024910},
 keywords = {academic integrity, collusion, plagiarism, programming education},
} 

@inproceedings{02Luxton-ReillyP17,
 author = {Andrew Luxton-Reilly and Andrew Petersen},
 title = {The Compound Nature of Novice Programming Assessments},
 booktitle = {Proceedings of the Nineteenth Australasian Computing Education Conference},
 series = {ACE '17},
 year = {2017},
 isbn = {978-1-4503-4823-2},
 location = {Geelong, VIC, Australia},
 pages = {26--35},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/3013499.3013500},
 doi = {10.1145/3013499.3013500},
 acmid = {3013500},
 keywords = {CS1, assessments, concepts, exams, novice programming, questions, syntax},
 comment={<b>Best Paper Award</b>},
}

@inproceedings{11AhadiH16,
 author = {Alireza Ahadi and Arto Hellas and Petri Ihantola and Ari Korhonen and Andrew Petersen},
 title = {Replication in Computing Education Research: Researcher Attitudes and Experiences},
 booktitle = {Proceedings of the 16th Koli Calling International Conference on Computing Education Research},
 series = {Koli Calling '16},
 year = {2016},
 isbn = {978-1-4503-4770-9},
 location = {Koli, Finland},
 pages = {2--11},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2999541.2999554},
 doi = {10.1145/2999541.2999554},
 acmid = {2999554},
 keywords = {computing education research, publication bias, replication, reproduction, research process, validation, verification},
} 

@inproceedings{11PetersenC16,
 author = {Andrew Petersen and Michelle Craig and Jennifer Campbell and Anya Tafliovich},
 title = {Revisiting Why Students Drop CS1},
 booktitle = {Proceedings of the 16th Koli Calling International Conference on Computing Education Research},
 series = {Koli Calling '16},
 year = {2016},
 isbn = {978-1-4503-4770-9},
 location = {Koli, Finland},
 pages = {71--80},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2999541.2999552},
 doi = {10.1145/2999541.2999552},
 acmid = {2999552},
 keywords = {CS1, dropping, retention},
 comment = {<b>Honorary Mention: Runner-up for best paper</b>}
} 

@inproceedings{BatesP11,
  author    = {Rebecca Bates and
               Andrew Petersen},
  title     = {Implementing Social Learning Strategies: Team Testing},
  booktitle = {American Society for Engineering Education (ASEE) Annual Conference Proceedings},
  year      = {2011},
  comment   = {<b>National Best Zone Paper</b>}
}

@article{04SzurmarkP10,
  author    = {Joanna Szurmak and
               Andrew Petersen},
  title     = {Learning Outcomes Assessment Matrix ({LOAM}): a Software-Supported Process for Identifying and Scaffolding Complex Learning Outcomes},
  booktitle = {Ubiquitous Learning},
  pages     = {8},
  volume    = {3},
  issue     = {2},
  month     = {April},
  year      = {2010}
}

inproceedings{DBLP:conf/acsc/CraigP16,
  author    = {Michelle Craig and
               Andrew Petersen},
  title     = {Student difficulties with pointer concepts in {C}},
  booktitle = {Proceedings of the Australasian Computer Science Week Multiconference,
               Canberra, Australia, February 2-5, 2016},
  pages     = {8:1--8:10},
  year      = {2016},
  url       = {http://doi.acm.org/10.1145/2843043.2843348},
  doi       = {10.1145/2843043.2843348},
  timestamp = {Thu, 11 Feb 2016 15:30:56 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/acsc/CraigP16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{08DBLP:conf/icer/HovemeyerHPS16,
  author    = {David Hovemeyer and
               Arto Hellas and
               Andrew Petersen and
               Jaime Spacco},
  title     = {Control-Flow-Only Abstract Syntax Trees for Analyzing Students' Programming
               Progress},
  booktitle = {Proceedings of the 2016 {ACM} Conference on International Computing
               Education Research, {ICER} 2016, Melbourne, VIC, Australia, September
               8-12, 2016},
  pages     = {63--72},
  year      = {2016},
  url       = {http://doi.acm.org/10.1145/2960310.2960326},
  doi       = {10.1145/2960310.2960326},
  timestamp = {Fri, 19 Aug 2016 09:39:36 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/icer/HovemeyerHPS16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{07DBLP:conf/iticse/PetersenCD16,
  author    = {Andrew Petersen and
               Michelle Craig and
               Paul Denny},
  title     = {Employing Multiple-Answer Multiple Choice Questions},
  booktitle = {Proceedings of the 2016 {ACM} Conference on Innovation and Technology
               in Computer Science Education},
  pages     = {252--253},
  year      = {2016},
  url       = {http://doi.acm.org/10.1145/2899415.2925503},
  doi       = {10.1145/2899415.2925503},
  timestamp = {Sun, 10 Jul 2016 19:07:31 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/iticse/PetersenCD16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

inproceedings{DBLP:conf/sigcse/TafliovichPC16,
  author    = {Anya Tafliovich and
               Andrew Petersen and
               Jennifer Campbell},
  title     = {Evaluating Student Teams: Do Educators Know What Students Think?},
  booktitle = {Proceedings of the 47th {ACM} Technical Symposium on Computing Science
               Education, Memphis, TN, USA, March 02 - 05, 2016},
  pages     = {181--186},
  year      = {2016},
  url       = {http://doi.acm.org/10.1145/2839509.2844647},
  doi       = {10.1145/2839509.2844647},
  timestamp = {Fri, 12 Feb 2016 08:43:53 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/sigcse/TafliovichPC16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{07DBLP:conf/iticse/IhantolaVABBEIK15,
  author    = {Petri Ihantola and
               Arto Vihavainen and
               Alireza Ahadi and
               Matthew Butler and
               J{\"{u}}rgen B{\"{o}}rstler and
               Stephen H. Edwards and
               Essi Isohanni and
               Ari Korhonen and
               Andrew Petersen and
               Kelly Rivers and
               Miguel {\'{A}}ngel Rubio and
               Judy Sheard and
               Bronius Skupas and
               Jaime Spacco and
               Claudia Szabo and
               Daniel Toll},
  title     = {Educational Data Mining and Learning Analytics in Programming: Literature
               Review and Case Studies},
  booktitle = {Proceedings of the 2015 ITiCSE Working Group Reports, {ITICSE-WGR}
               2015, Vilnius, Lithuania, July 4-8, 2015},
  pages     = {41--63},
  year      = {2015},
  url       = {http://doi.acm.org/10.1145/2858796.2858798},
  doi       = {10.1145/2858796.2858798},
  timestamp = {Thu, 18 Aug 2016 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/iticse/IhantolaVABBEIK15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

inproceedings{07DBLP:conf/iticse/KarpovaDHP15,
  author    = {Olessia Karpova and
               Noel D'Souza and
               Diane Horton and
               Andrew Petersen},
  title     = {{RAPT:} Relational Algebra Parsing Tools},
  booktitle = {Proceedings of the 2015 {ACM} Conference on Innovation and Technology
               in Computer Science Education},
  pages     = {334},
  year      = {2015},
  url       = {http://doi.acm.org/10.1145/2729094.2754862},
  doi       = {10.1145/2729094.2754862},
  timestamp = {Sat, 27 Jun 2015 15:44:10 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/iticse/KarpovaDHP15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{07DBLP:conf/iticse/ParreiraPC15,
  author    = {Daniel Marchena Parreira and
               Andrew Petersen and
               Michelle Craig},
  title     = {{PCRS-C:} Helping Students Learn {C}},
  booktitle = {Proceedings of the 2015 {ACM} Conference on Innovation and Technology
               in Computer Science Education},
  pages     = {347},
  year      = {2015},
  url       = {http://doi.acm.org/10.1145/2729094.2754852},
  doi       = {10.1145/2729094.2754852},
  timestamp = {Sat, 27 Jun 2015 15:44:10 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/iticse/ParreiraPC15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{11DBLP:conf/kolicalling/PetersenSV15,
  author    = {Andrew Petersen and
               Jaime Spacco and
               Arto Vihavainen},
  title     = {An exploration of error quotient in multiple contexts},
  booktitle = {Proceedings of the 15th Koli Calling Conference on Computing Education
               Research, Koli, Finland, November 19-22, 2015},
  pages     = {77--86},
  year      = {2015},
  url       = {http://doi.acm.org/10.1145/2828959.2828966},
  doi       = {10.1145/2828959.2828966},
  timestamp = {Mon, 23 Nov 2015 19:16:05 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/kolicalling/PetersenSV15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{11DBLP:conf/kolicalling/SmithZP15,
  author    = {Stewart D. Smith and
               Nicholas Zemljic and
               Andrew Petersen},
  title     = {Modern goto: novice programmer usage of non-standard control flow},
  booktitle = {Proceedings of the 15th Koli Calling Conference on Computing Education
               Research, Koli, Finland, November 19-22, 2015},
  pages     = {171--172},
  year      = {2015},
  url       = {http://doi.acm.org/10.1145/2828959.2828980},
  doi       = {10.1145/2828959.2828980},
  timestamp = {Mon, 23 Nov 2015 19:16:05 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/kolicalling/SmithZP15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

inproceedings{DBLP:conf/sigcse/TafliovichPC15,
  author    = {Anya Tafliovich and
               Andrew Petersen and
               Jennifer Campbell},
  title     = {On the Evaluation of Student Team Software Development Projects},
  booktitle = {Proceedings of the 46th {ACM} Technical Symposium on Computer Science
               Education, Kansas City, MO, USA, March 4-7, 2015},
  pages     = {494--499},
  year      = {2015},
  url       = {http://doi.acm.org/10.1145/2676723.2677223},
  doi       = {10.1145/2676723.2677223},
  timestamp = {Thu, 26 Feb 2015 19:17:42 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/sigcse/TafliovichPC15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{03DBLP:conf/sigcse/CherenkovaZP14,
  author    = {Yuliya Cherenkova and
               Daniel Zingaro and
               Andrew Petersen},
  title     = {Identifying challenging {CS1} concepts in a large problem dataset},
  booktitle = {The 45th {ACM} Technical Symposium on Computer Science Education,
               {SIGCSE} '14, Atlanta, GA, {USA} - March 05 - 08, 2014},
  pages     = {695--700},
  year      = {2014},
  url       = {http://doi.acm.org/10.1145/2538862.2538966},
  doi       = {10.1145/2538862.2538966},
  timestamp = {Mon, 24 Feb 2014 13:38:26 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/sigcse/CherenkovaZP14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

inproceedings{03DBLP:conf/sigcse/HovemeyerSDEKPZ14,
  author    = {David Hovemeyer and
               Jaime Spacco and
               Robert C. Duvall and
               Stephen H. Edwards and
               Amruth N. Kumar and
               Andrew Petersen and
               Daniel Zingaro},
  title     = {Using and sharing programming exercises to improve introductory courses},
  booktitle = {The 45th {ACM} Technical Symposium on Computer Science Education,
               {SIGCSE} '14, Atlanta, GA, {USA} - March 05 - 08, 2014},
  pages     = {737},
  year      = {2014},
  url       = {http://doi.acm.org/10.1145/2538862.2544261},
  doi       = {10.1145/2538862.2544261},
  timestamp = {Thu, 28 May 2015 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/sigcse/HovemeyerSDEKPZ14},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  comment = {Abstract only.}
}

inproceedings{DBLP:conf/sigcse/TafliovichCP13,
  author    = {Anya Tafliovich and
               Jennifer Campbell and
               Andrew Petersen},
  title     = {A student perspective on prior experience in {CS1}},
  booktitle = {The 44th {ACM} Technical Symposium on Computer Science Education,
               {SIGCSE} '13, Denver, CO, USA, March 6-9, 2013},
  pages     = {239--244},
  year      = {2013},
  url       = {http://doi.acm.org/10.1145/2445196.2445270},
  doi       = {10.1145/2445196.2445270},
  timestamp = {Sat, 09 Mar 2013 14:11:35 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/sigcse/TafliovichCP13},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{03DBLP:conf/sigcse/ZingaroCKP13,
  author    = {Daniel Zingaro and
               Yuliya Cherenkova and
               Olessia Karpova and
               Andrew Petersen},
  title     = {Facilitating code-writing in {PI} classes},
  booktitle = {The 44th {ACM} Technical Symposium on Computer Science Education,
               {SIGCSE} '13, Denver, CO, USA, March 6-9, 2013},
  pages     = {585--590},
  year      = {2013},
  url       = {http://doi.acm.org/10.1145/2445196.2445369},
  doi       = {10.1145/2445196.2445369},
  timestamp = {Sat, 09 Mar 2013 14:11:35 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/sigcse/ZingaroCKP13},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

inproceedings{DBLP:conf/sigcse/CraigPP12,
  author    = {Michelle Craig and
               Sarah Petersen and
               Andrew Petersen},
  title     = {Following a thread: knitting patterns and program tracing},
  booktitle = {Proceedings of the 43rd {ACM} technical symposium on Computer science
               education, {SIGCSE} 2012, Raleigh, NC, USA, February 29 - March 3,
               2012},
  pages     = {233--238},
  year      = {2012},
  url       = {http://doi.acm.org/10.1145/2157136.2157204},
  doi       = {10.1145/2157136.2157204},
  timestamp = {Mon, 05 Mar 2012 08:17:41 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/sigcse/CraigPP12},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{03DBLP:conf/sigcse/ZingaroPC12,
  author    = {Daniel Zingaro and
               Andrew Petersen and
               Michelle Craig},
  title     = {Stepping up to integrative questions on {CS1} exams},
  booktitle = {Proceedings of the 43rd {ACM} technical symposium on Computer science
               education, {SIGCSE} 2012, Raleigh, NC, USA, February 29 - March 3,
               2012},
  pages     = {253--258},
  year      = {2012},
  url       = {http://doi.acm.org/10.1145/2157136.2157215},
  doi       = {10.1145/2157136.2157215},
  timestamp = {Mon, 05 Mar 2012 08:17:41 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/sigcse/ZingaroPC12},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{03DBLP:conf/sigcse/PetersenCZ11,
  author    = {Andrew Petersen and
               Michelle Craig and
               Daniel Zingaro},
  title     = {Reviewing {CS1} exam question content},
  booktitle = {Proceedings of the 42nd {ACM} technical symposium on Computer science
               education, {SIGCSE} 2011, Dallas, TX, USA, March 9-12, 2011},
  pages     = {631--636},
  year      = {2011},
  url       = {http://doi.acm.org/10.1145/1953163.1953340},
  doi       = {10.1145/1953163.1953340},
  timestamp = {Mon, 05 Mar 2012 08:55:53 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/sigcse/PetersenCZ11},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}
