@inproceedings{03Zavaleta25,
author = {Valeria Ramirez Osorio and Angela Zavaleta Bernuy and Bogdan Simion and Michael Liut},
title = {Understanding the Impact of Using Generative AI Tools in a Database Course},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701785},
doi = {10.1145/3641554.3701785},
abstract = {Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) have led to changes in educational practices by creating opportunities for personalized learning and immediate support. Computer science student perceptions and behaviors towards GenAI tools have been studied, but the effects of such tools on student learning have yet to be determined conclusively. We investigate the impact of GenAI tools on computing students' performance in a database course and aim to understand why students use GenAI tools in assignments. Our mixed-methods study (N=226) asked students to self-report whether they used a GenAI tool to complete a part of an assignment and why. Our results reveal that students utilizing GenAI tools performed better on the assignment part in which LLMs were permitted but did worse in other parts of the assignment and in the course overall. Also, those who did not use GenAI tools viewed more discussion board posts and participated more than those who used ChatGPT. This suggests that using GenAI tools may not lead to better skill development or mental models, at least not if the use of such tools is unsupervised, and that engagement with official course help supports may be affected. Further, our thematic analysis of reasons for using or not using GenAI tools, helps understand why students are drawn to these tools. Shedding light into such aspects empowers instructors to be proactive in how to encourage, supervise, and handle the use or integration of GenAI into courses, fostering good learning habits.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {959–965},
numpages = {7},
keywords = {computing education, databases, generative artificial intelligence, large language models, student behavior, student performance},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

inproceedings{03Harrington25,
author = {Brian Harrington and Aditya Kulkarni and Rohita Nalluri and Anagha Vadarevu and Angela Zavaleta Bernuy},
title = {Literature Mapping: A Scaffolded, Scalable, Low-Overhead Undergraduate Research Experience},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701938},
doi = {10.1145/3641554.3701938},
abstract = {There is a wealth of evidence that involving undergraduate students in research has positive impacts in a variety of areas, from representation and retention to outcomes and self-efficacy. However, developing and growing an undergraduate research program can be daunting, especially for institutions that do not have a large existing research enterprise. In this work, we detail a program that revolves around student-developed literature maps to help students gain the ability to read and assess research papers in a way that is accessible, robust, and requires relatively little faculty overhead. We further detail how this program has been run through 4 iterations, with a total of 47 students producing 5 posters or short papers, and 3 full papers. In this work, we provide our experiences using literature mapping projects to boot-strap an undergraduate research program and provide quantitative and qualitative analysis of the students who have participated. All of the materials, including sample spreadsheets, and scripts to generate LaTeX tables and figures are included for anyone wishing to un
dertake a literature mapping project of their own.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {464–470},
numpages = {7},
keywords = {literature mapping, literature review, undergraduate research},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{01Zavaleta25,
author = {Rita Garcia and Andrew Csizmadia and Janice L. Pearce and Bedour Alshaigy and Olga Glebova and Brian Harrington and Konstantinos Liaskos and Stephanie J. Lunn and Bonnie Mackellar and Usman Nasir and Raymond Pettit and Sandra Schulz and Craig Stewart and Angela Zavaleta Bernuy},
title = {An International Examination of Non-Technical Skills and Professional Dispositions in Computing -- Identifying the Present Day Academia-Industry Gap},
year = {2025},
isbn = {9798400712081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689187.3709610},
doi = {10.1145/3689187.3709610},
abstract = {Computing graduates are frequently reported by members of industry to lack in professional dispositions and/or non-technical skills (often referred to as "soft skills"). In this work, we conduct a gap analysis of the alignment between academic preparation and industry expectations through a three-pronged study. First, a literature review explored the academic perspective of how fostering professional dispositions and non-technical skills occurs in tertiary computing education. Second, a literature review identifying industry's expectations of those dispositions and skills for entry-level computing professionals. Finally, a mixed-methods approach, combining a survey and structured interviews of computing industry professionals to identify their opinions on the relative importance of those skills and dispositions. In each of these prongs, we additionally consider whether and how Diversity, Equity, Inclusion, and Accessibility (DEIA) may have been approached and/or incorporated.Our work uncovers a number of gaps. Several skills and dispositions, such as leadership, ethics, and inventiveness, are over-represented in the academic literature compared to industry's expectations, while others such as lifelong learning and professionalism are under-emphasised. Furthermore, some terms such as 'ethics' and 'professionalism' are defined differently by various stakeholder groups, leading to a gap between academic training and industry expectations. Finally, several skills and dispositions, such as collaboration, teamwork, communication, and leadership show evidence of exposure in academia, but require more scaffolded instruction to meet industry expectations. We also found a dearth of coverage in the literature and a lack of focus in industry for DEIA considerations.},
booktitle = {2024 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {124–174},
numpages = {51},
keywords = {DEIA, E&I, EDI, accessibility, diversity, equity, inclusion, industry expectations, non-technical skills, professional dispositions, professionalism},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{07Zavaleta24,
author = {Angela Zavaleta Bernuy and Naaz Sibia and Pan Chen and Jessica Jia-Ni Xu and Elexandra Tran and Runlong Ye and Viktoria Pammer-Schindler and Andrew Petersen and Joseph Jay Williams and Michael Liut},
title = {Does the Medium Matter? An Exploration of Voice-Interaction for Self-Explanations},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661596},
doi = {10.1145/3643834.3661596},
abstract = {This research evaluates voice-based self-explanations as a pedagogical tool in preparation for lectures, assesses user preferences between voice and text, and derives design insights. We report two studies: Study 1, a quasi-experimental field study, with 247 participants divided into voice-based (N = 83), text-based (N = 81), and choice (N = 83) conditions. Study 2 uses semi-structured interviews (N = 16) to explore perceptions of the interaction paradigms in-depth. Results from the first study revealed a general preference for text, though voice users produced longer responses and more topic-related keywords. Over time, the preference for voice increased among students, from 10\% to 46\%, when given a choice. Study 2 suggested that factors like social presence contribute to hesitance toward voice-based explanations, with a cognitive load, self-confidence, and performance anxiety also influencing medium preferences. Our findings highlight design recommendations and demonstrate the potential of voice-based self-explanations in educational settings, indicating that mixed interfaces might better meet diverse needs.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {86–101},
numpages = {16},
keywords = {Active Learning, Explanation Prompts, Long-Term Memory, Self-Explanations, Student Performance, Text Explanations, Voice Explanations, Voice-based Interaction},
location = {IT University of Copenhagen, Denmark},
series = {DIS '24}
}

inproceedings{04Sibia24,
author = {Naaz Sibia and Angela Zavaleta Bernuy and Elexandra Tran and Jessica Jia-Ni Xu and Joseph Jay Williams and Andrew Petersen and Michael Liut},
title = {Exploring Self-Explanations in a Flipped Database Course},
year = {2024},
isbn = {9798400706783},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663649.3664374},
doi = {10.1145/3663649.3664374},
abstract = {Self-explanations show promise for engaging students with preparatory materials, yet research into the types of self-explanations submitted in computing is limited. This paper examines student perceptions of self-explanation prompts in a flipped databases course, building on existing research that highlights the advantages of self-explanations in such contexts. We present our findings on students’ perceptions of the utility of self-explanation prompts and analyze
the nature of the explanations generated across distinct topics. The results suggest that self-explanations not only facilitate a deeper understanding of the subject matter but also promote the discovery of new connections and examples through rewording explanations. Furthermore, errors within self-explanations offer valuable insights for the early identification of misconceptions.},
booktitle = {Proceedings of the 3rd International Workshop on Data Systems Education: Bridging Education Practice with Education Research},
pages = {20–26},
numpages = {7},
keywords = {Active Learning, Flipped Databases Course, Self-Explanations},
location = {Santiago, AA, Chile},
series = {DataEd '24}
}

@inproceedings{12Zavaleta23,
author = {Barbara J. Ericson and Janice L. Pearce and Susan H. Rodger and Andrew Csizmadia and Rita Garcia and Francisco J. Gutierrez and Konstantinos Liaskos and Aadarsh Padiyath and Michael James Scott and David H. Smith and Jayakrishnan M. Warriem and Angela Zavaleta Bernuy},
title = {Multi-Institutional Multi-National Studies of Parsons Problems},
year = {2023},
isbn = {9798400704055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623762.3633498},
doi = {10.1145/3623762.3633498},
abstract = {Students are often asked to learn programming by writing code from scratch. However, many novices struggle to write code and get frustrated when their code does not work. Parsons problems can reduce the difficulty of a coding problem by providing mixed-up blocks the learner rearranges into the correct order. These mixed-up blocks can include distractor blocks that are not needed in a correct solution. Distractor blocks can include common errors, which may help students learn to recognize and fix such errors. Evidence suggests students find Parsons problems engaging, useful for learning to program, and typically easier and faster to solve than writing code from scratch, but with equivalent learning gains. Most research on Parsons problems prior to this work has been conducted at a single institution. This work addresses the need for replication across multiple contexts.A 2022 ITiCSE Parsons Problems Working Group conducted an extensive literature review of Parsons problems, designed several experimental studies for Parsons problems in Python, and created 'study-in-a-box' materials to help instructors run the experimental studies, but the 2022 working group had only sufficient time to pilot two of these studies.Our 2023 ITiCSE Parsons Problems Working Group reviewed these studies, revised some of the studies, expanded both the programming and natural languages used in some of the studies, created new studies, conducted think-aloud observations on some of the studies, and ran both revised as well as new experimental studies. The think-aloud observations and experimental studies provide evidence for using Parsons problems to help students learn common algorithms such as swap, and the usefulness of distractors in helping students learn to recognize, fix, and avoid common errors. In addition, our 2023 ITiCSE Parsons Problems Working Group reviewed Parsons problem papers published after the 2022 literature review and provided a literature review of multi-national (MIMN) studies conducted in computer science education to better understand the motivations and challenges in performing such MIMN studies.In summary, this article contributes an analysis of recent Parsons problem research papers, an itemization of considerations for MIMN studies, the results from our MIMN studies of Parsons problems, and a discussion of recent and future directions for MIMN studies of Parsons problems and more generally.},
booktitle = {Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {57–107},
numpages = {51},
keywords = {parson's puzzles, multi-institutional study, parsons puzzles, parson's programming puzzles, multi-institutional multi-national study, parson's problems, parsons problems, multi-national study, code puzzles},
location = {<conf-loc>, <city>Turku</city>, <country>Finland</country>, </conf-loc>},
series = {ITiCSE-WGR '23}
}
